{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a222758-dba7-4bf2-872b-b97935ed3ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Import Successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "print(\"Libraries Import Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c5f9c6-93a9-4f14-a8eb-f38812f89ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_folder = r\"C:\\Users\\M. Faizan\\Desktop\\SE\\6th\\Data_Science_Assign2\\raw\\electricity_raw_data\"\n",
    "weather_folder = r\"C:\\Users\\M. Faizan\\Desktop\\SE\\6th\\Data_Science_Assign2\\raw\\weather_raw_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c8f0f0-c45d-466f-be71-af2e48fec03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data Columns: Index(['date', 'temperature_2m'], dtype='object')\n",
      "No missing data found. File not created.\n",
      "Updated data saved to: C:\\Users\\M. Faizan\\Desktop\\SE\\6th\\Saved\\cleaned_and_featured_data.csv\n",
      "Data Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 261035 entries, 0 to 1392802\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   datetime            261035 non-null  datetime64[ns]\n",
      " 1   subba               261035 non-null  category      \n",
      " 2   subba-name          261035 non-null  category      \n",
      " 3   parent              261035 non-null  category      \n",
      " 4   parent-name         261035 non-null  category      \n",
      " 5   electricity_demand  261035 non-null  float64       \n",
      " 6   value-units         261035 non-null  category      \n",
      " 7   temperature_2m      261035 non-null  float64       \n",
      " 8   hour                261035 non-null  int32         \n",
      " 9   day                 261035 non-null  int32         \n",
      " 10  month               261035 non-null  int32         \n",
      " 11  year                261035 non-null  int32         \n",
      " 12  day_of_week         261035 non-null  int32         \n",
      " 13  is_weekend          261035 non-null  int64         \n",
      " 14  season              261035 non-null  category      \n",
      "dtypes: category(6), datetime64[ns](1), float64(2), int32(5), int64(1)\n",
      "memory usage: 16.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load electricity data (JSON files)\n",
    "electricity_data = []\n",
    "for file_path in glob.glob(os.path.join(electricity_folder, \"*.json\")):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        records = data.get(\"response\", {}).get(\"data\", [])\n",
    "        electricity_data.extend(records)\n",
    "\n",
    "# Convert to DataFrame and standardize column names\n",
    "electricity_df = pd.DataFrame(electricity_data)\n",
    "electricity_df.rename(columns={\"period\": \"datetime\", \"value\": \"electricity_demand\"}, inplace=True)\n",
    "electricity_df[\"datetime\"] = pd.to_datetime(electricity_df[\"datetime\"], format=\"%Y-%m-%dT%H\", errors='coerce')\n",
    "\n",
    "# Load weather data (CSV files)\n",
    "weather_data = []\n",
    "for file_path in glob.glob(os.path.join(weather_folder, \"*.csv\")):\n",
    "    df = pd.read_csv(file_path, encoding=\"utf-8\", header=0)\n",
    "    df.columns = df.columns.str.strip()  # Remove leading/trailing spaces\n",
    "    weather_data.append(df)\n",
    "\n",
    "# Merge all weather data into a single DataFrame\n",
    "weather_df = pd.concat(weather_data, ignore_index=True)\n",
    "print(\"Weather Data Columns:\", weather_df.columns)  # Debugging step\n",
    "\n",
    "# Ensure the correct datetime column is used and convert to datetime format\n",
    "if \"datetime\" in weather_df.columns:\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"datetime\"], errors='coerce')\n",
    "elif \"timestamp\" in weather_df.columns:\n",
    "    weather_df.rename(columns={\"timestamp\": \"datetime\"}, inplace=True)\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"datetime\"], errors='coerce')\n",
    "elif \"date\" in weather_df.columns:  # Your dataset has 'date' instead of 'datetime'\n",
    "    weather_df.rename(columns={\"date\": \"datetime\"}, inplace=True)\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"datetime\"], errors='coerce')\n",
    "else:\n",
    "    raise KeyError(\"No valid datetime column found in weather data\")\n",
    "\n",
    "# Drop rows with invalid datetime values\n",
    "weather_df.dropna(subset=[\"datetime\"], inplace=True)\n",
    "\n",
    "#  Fix: Ensure both datetime columns have the same format (remove timezone differences)\n",
    "electricity_df[\"datetime\"] = electricity_df[\"datetime\"].dt.tz_localize(None)\n",
    "weather_df[\"datetime\"] = weather_df[\"datetime\"].dt.tz_localize(None)\n",
    "\n",
    "# Merge electricity and weather data on the datetime column\n",
    "final_df = pd.merge(electricity_df, weather_df, on=\"datetime\", how=\"inner\")\n",
    "\n",
    "#  Handling Duplicates and Inconsistencies\n",
    "# Remove duplicate rows to maintain data integrity\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "\n",
    "#  Ensure electricity_demand is numeric\n",
    "final_df[\"electricity_demand\"] = pd.to_numeric(final_df[\"electricity_demand\"], errors=\"coerce\")\n",
    "final_df.dropna(subset=[\"electricity_demand\"], inplace=True)  # Drop rows with NaN values\n",
    "\n",
    "#  Identify and remove outliers in numerical columns using IQR method\n",
    "Q1 = final_df[\"electricity_demand\"].quantile(0.25)\n",
    "Q3 = final_df[\"electricity_demand\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers\n",
    "final_df = final_df[(final_df[\"electricity_demand\"] >= lower_bound) & (final_df[\"electricity_demand\"] <= upper_bound)]\n",
    "\n",
    "#  Feature Engineering\n",
    "# Extract additional temporal features for analysis\n",
    "final_df[\"hour\"] = final_df[\"datetime\"].dt.hour\n",
    "final_df[\"day\"] = final_df[\"datetime\"].dt.day\n",
    "final_df[\"month\"] = final_df[\"datetime\"].dt.month\n",
    "final_df[\"year\"] = final_df[\"datetime\"].dt.year\n",
    "final_df[\"day_of_week\"] = final_df[\"datetime\"].dt.dayofweek\n",
    "final_df[\"is_weekend\"] = final_df[\"day_of_week\"].apply(lambda x: 1 if x >= 5 else 0)\n",
    "final_df[\"season\"] = final_df[\"month\"].apply(lambda x: (\"Winter\" if x in [12, 1, 2] else\n",
    "                                                           \"Spring\" if x in [3, 4, 5] else\n",
    "                                                           \"Summer\" if x in [6, 7, 8] else\n",
    "                                                           \"Fall\"))\n",
    "\n",
    "# Normalize numerical features (Min-Max Scaling)\n",
    "numeric_cols = [\"electricity_demand\"]\n",
    "for col in numeric_cols:\n",
    "    final_df[col] = (final_df[col] - final_df[col].min()) / (final_df[col].max() - final_df[col].min())\n",
    "\n",
    "# Convert categorical columns to category dtype for efficiency\n",
    "categorical_cols = [\"subba\", \"subba-name\", \"parent\", \"parent-name\", \"value-units\", \"season\"]\n",
    "for col in categorical_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].astype(\"category\")\n",
    "\n",
    "#  Ensure the processed directory exists\n",
    "output_dir = r\"C:\\Users\\M. Faizan\\Desktop\\SE\\6th\\Saved\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "#  Missing Data Analysis\n",
    "missing_data = final_df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(final_df)) * 100\n",
    "missing_data_path = os.path.join(output_dir, \"missing_data_analysis.csv\")\n",
    "missing_data_df = pd.DataFrame({\"Missing Values\": missing_data, \"Percentage\": missing_percentage})\n",
    "\n",
    "# Save missing data analysis only if missing values exist\n",
    "if missing_data_df[\"Missing Values\"].sum() > 0:\n",
    "    missing_data_df.to_csv(missing_data_path, index=True)\n",
    "    print(f\"Missing data analysis saved to: {missing_data_path}\")\n",
    "else:\n",
    "    print(\"No missing data found. File not created.\")\n",
    "\n",
    "# Save updated data\n",
    "updated_data_path = os.path.join(output_dir, \"cleaned_and_featured_data.csv\")\n",
    "final_df.to_csv(updated_data_path, index=False)\n",
    "print(f\"Updated data saved to: {updated_data_path}\")\n",
    "\n",
    "# Summary of the final dataset\n",
    "print(\"Data Summary:\")\n",
    "print(final_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486b213-6685-4350-8ad8-20d73dfc337c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
